{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347520df11b3027e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fcb8704f34334f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:13.923216Z",
     "start_time": "2023-10-16T14:37:13.814857Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.downloader\n",
    "\n",
    "from seqeval.metrics import f1_score as f1_score_seqeval\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import IOB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4d9acf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "word2vec_goog1e_news: gensim.models.keyedvectors.KeyedVectors = gensim.downloader.load('word2vec-google-news-300')\n",
    "word2vec_goog1e_news.add_vector(\"<pad>\", np.zeros(300))\n",
    "pad_index = word2vec_goog1e_news.key_to_index[\"<pad>\"]\n",
    "embedding_weights = torch.FloatTensor(word2vec_goog1e_news.vectors)\n",
    "vocab = word2vec_goog1e_news.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_pd_series_to_lsit(list_of_text):\n",
    "    tokenized = []\n",
    "    for sentence in list_of_text:\n",
    "        tokenized.append(word_tokenize(sentence.lower()))\n",
    "    return tokenized\n",
    "\n",
    "def format_label(label):\n",
    "    return torch.unsqueeze(torch.tensor(label.to_list()), axis=1).tolist()\n",
    "\n",
    "def indexify(data):\n",
    "    setences = []\n",
    "    for sentence in data:\n",
    "        s = [vocab[token] if token in vocab\n",
    "            else vocab['UNK']\n",
    "            for token in sentence]\n",
    "        setences.append(s)\n",
    "    return setences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e894b3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(filepath_or_buffer=\"TREC_dataset/modified_training_data.csv\", sep=\",\") \n",
    "test_data = pd.read_csv(filepath_or_buffer=\"TREC_dataset/modified_test_data.csv\", sep=\",\")\n",
    "\n",
    "X = training_data[\"text\"]\n",
    "y = training_data[\"label-coarse\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=500)\n",
    "\n",
    "X_test = test_data[\"text\"]\n",
    "y_test = test_data[\"label-coarse\"]\n",
    "\n",
    "X_train_lst = X_train.to_list()\n",
    "X_val_lst = X_val.to_list()\n",
    "X_test_lst = X_test.to_list()\n",
    "\n",
    "X_train_tokenized = tokenize_pd_series_to_lsit(X_train_lst)\n",
    "X_val_tokenized = tokenize_pd_series_to_lsit(X_val_lst)\n",
    "X_test_tokenized = tokenize_pd_series_to_lsit(X_test_lst)\n",
    "\n",
    "no_of_labels = max(y_train.to_list()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tokenized_indexified = indexify(X_train_tokenized)\n",
    "X_val_tokenized_indexified = indexify(X_val_tokenized)\n",
    "X_test_tokenized_indexified = indexify(X_test_tokenized)\n",
    "\n",
    "y_train_formatted = format_label(y_train)\n",
    "y_val_formatted = format_label(y_val)\n",
    "y_test_formatted = format_label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5800cc7f3fc93583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.011887Z",
     "start_time": "2023-10-16T14:37:13.882822Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_iterator(sentences, labels, total_size: int, batch_size: int, shuffle: bool=False):\n",
    "    # make a list that decides the order in which we go over the data- this avoids explicit shuffling of data\n",
    "    order = list(range(total_size))\n",
    "    if shuffle:\n",
    "        random.seed(230)\n",
    "        random.shuffle(order)\n",
    "\n",
    "    # one pass over data\n",
    "    for i in range((total_size+1)//batch_size):\n",
    "        # fetch sentences and tags\n",
    "        batch_sentences = [sentences[idx] for idx in order[i*batch_size:(i+1)*batch_size]]\n",
    "        batch_tags = [labels[idx] for idx in order[i*batch_size:(i+1)*batch_size]]\n",
    "\n",
    "        # compute length of longest sentence in batch\n",
    "        batch_max_len = max([len(s) for s in batch_sentences])\n",
    "\n",
    "        # prepare a numpy array with the data, initialising the data with pad_ind and all labels with -1\n",
    "        # initialising labels to -1 differentiates tokens with tags from PADding tokens\n",
    "        batch_data = vocab['<pad>']*np.ones((len(batch_sentences), batch_max_len))\n",
    "        # batch_labels = -1*np.ones((len(batch_sentences), batch_max_len))\n",
    "        batch_labels = -1*np.ones(len(batch_sentences))\n",
    "        batch_labels = batch_labels.reshape(-1, 1)\n",
    "\n",
    "        # print(f\"batch_data.shape = {batch_data.shape}\")\n",
    "        # print(f\"batch_labels.shape = {batch_labels.shape}\")\n",
    "\n",
    "        # copy the data to the numpy array\n",
    "        for j in range(len(batch_sentences)):\n",
    "            cur_len = len(batch_sentences[j])\n",
    "            batch_data[j][:cur_len] = batch_sentences[j]\n",
    "            batch_labels[j][:cur_len] = batch_tags[j]\n",
    "\n",
    "        # since all data are indices, we convert them to torch LongTensors\n",
    "        batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels)\n",
    "        \n",
    "        # convert them to Variables to record operations in the computational graph\n",
    "        batch_data, batch_labels = Variable(batch_data), Variable(batch_labels)\n",
    "\n",
    "        yield batch_data, batch_labels, batch_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9aa7ca1ef91b423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.012307Z",
     "start_time": "2023-10-16T14:37:13.894126Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the standard way to define your own network in PyTorch. You typically choose the components\n",
    "    (e.g. LSTMs, linear layers etc.) of your network in the __init__ function. You then apply these layers\n",
    "    on the input step-by-step in the forward function. You can use torch.nn.functional to apply functions\n",
    "    such as F.relu, F.sigmoid, F.softmax. Be careful to ensure your dimensions are correct after each step.\n",
    "\n",
    "    You are encouraged to have a look at the network in pytorch/vision/model/net.py to get a better sense of how\n",
    "    you can go about defining your own network.\n",
    "\n",
    "    The documentation for all the various components available to you is here: http://pytorch.org/docs/master/nn.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_weights, embedding_dim, lstm_hidden_dim, number_of_tags):\n",
    "        \"\"\"\n",
    "        We define an recurrent network that predicts the NER tags for each token in the sentence. The components\n",
    "        required are:\n",
    "\n",
    "        - an embedding layer: this layer maps each index in range(params.vocab_size) to a params.embedding_dim vector\n",
    "        - lstm: applying the LSTM on the sequential input returns an output for each token in the sentence\n",
    "        - fc: a fully connected layer that converts the LSTM output for each token to a distribution over NER tags\n",
    "\n",
    "        Args:\n",
    "            params: (Params) contains vocab_size, embedding_dim, lstm_hidden_dim\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # the embedding takes as input the vocab_size and the embedding_dim\n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weights, padding_idx=pad_index)\n",
    "\n",
    "        # the LSTM takes as input the size of its input (embedding_dim), its hidden size\n",
    "        # for more details on how to use it, check out the documentation\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            lstm_hidden_dim, batch_first=True)\n",
    "\n",
    "        # the fully connected layer transforms the output to give the final output layer\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, number_of_tags)\n",
    "\n",
    "    def forward(self, s):\n",
    "        \"\"\"\n",
    "        This function defines how we use the components of our network to operate on an input batch.\n",
    "\n",
    "        Args:\n",
    "            s: (Variable) contains a batch of sentences, of dimension batch_size x seq_len, where seq_len is\n",
    "               the length of the longest sentence in the batch. For sentences shorter than seq_len, the remaining\n",
    "               tokens are PADding tokens. Each row is a sentence with each element corresponding to the index of\n",
    "               the token in the vocab.\n",
    "\n",
    "        Returns:\n",
    "            out: (Variable) dimension batch_size*seq_len x num_tags with the log probabilities of tokens for each token\n",
    "                 of each sentence.\n",
    "\n",
    "        Note: the dimensions after each step are provided\n",
    "        \"\"\"\n",
    "        #                                -> batch_size x seq_len\n",
    "        # apply the embedding layer that maps each token to its embedding\n",
    "        # dim: batch_size x seq_len x embedding_dim\n",
    "        s = self.embedding(s)\n",
    "\n",
    "        # run the LSTM along the sentences of length seq_len\n",
    "        # dim: batch_size x seq_len x lstm_hidden_dim\n",
    "        s, _ = self.lstm(s)\n",
    "        # make the Variable contiguous in memory (a PyTorch artefact)\n",
    "        # s = s.contiguous()\n",
    "        # reshape the Variable so that each row contains one token\n",
    "        # dim: batch_size*seq_len x lstm_hidden_dim\n",
    "        # s = s.view(-1, s.shape[2])\n",
    "\n",
    "        # Changed\n",
    "        s = s[:, -1, :]\n",
    "        \n",
    "        # apply the fully connected layer and obtain the output (before softmax) for each token\n",
    "        s = self.fc(s)                   # dim: batch_size*seq_len x num_tags\n",
    "\n",
    "        # apply log softmax on each token's output (this is recommended over applying softmax\n",
    "        # since it is numerically more stable)\n",
    "        # return F.log_softmax(s, dim=1)   # dim: batch_size*seq_len x num_tags\n",
    "        return F.softmax(s, dim=1)   # dim: batch_size*seq_len x num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba90bdc3ae13684a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.012907Z",
     "start_time": "2023-10-16T14:37:13.899592Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the cross entropy loss given outputs from the model and labels for all tokens. Exclude loss terms\n",
    "    for PADding tokens.\n",
    "\n",
    "    Args:\n",
    "        outputs: (Variable) dimension batch_size*seq_len x num_tags - log softmax output of the model\n",
    "        labels: (Variable) dimension batch_size x seq_len where each element is either a label in [0, 1, ... num_tag-1],\n",
    "                or -1 in case it is a PADding token.\n",
    "\n",
    "    Returns:\n",
    "        loss: (Variable) cross entropy loss for all tokens in the batch\n",
    "\n",
    "    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n",
    "          demonstrates how you can easily define a custom loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    # reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    # since PADding tokens have label -1, we can generate a mask to exclude the loss from those terms\n",
    "    mask = (labels >= 0).float()\n",
    "\n",
    "    # indexing with negative values is not supported. Since PADded tokens have label -1, we convert them to a positive\n",
    "    # number. This does not affect training, since we ignore the PADded tokens with the mask.\n",
    "    labels = labels % outputs.shape[1]\n",
    "    num_tokens = int(torch.sum(mask))\n",
    "\n",
    "    # compute cross entropy loss for all tokens (except PADding tokens), by multiplying with mask.\n",
    "    \n",
    "    # return -torch.sum(outputs[range(outputs.shape[0]), labels]*mask)/ torch.sum(num_tokens)\n",
    "    a = outputs[range(outputs.shape[0]), labels]*mask\n",
    "    b = -torch.sum(a)\n",
    "    c = num_tokens\n",
    "    return b/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07330c216283eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.013393Z",
     "start_time": "2023-10-16T14:37:13.913339Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RunningAverage:\n",
    "    \"\"\"A simple class that maintains the running average of a quantity\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    loss_avg = RunningAverage()\n",
    "    loss_avg.update(2)\n",
    "    loss_avg.update(4)\n",
    "    loss_avg() = 3\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.total = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.total += val\n",
    "        self.steps += 1\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.total / float(self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84b8f1d154a50053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.014581Z",
     "start_time": "2023-10-16T14:37:13.927378Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, data_iterator, metrics, num_steps):\n",
    "    \"\"\"Train the model on `num_steps` batches\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        optimizer: (torch.optim) optimizer for parameters of model\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        data_iterator: (generator) a generator that generates batches of data and labels\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # summary for current training loop and a running average object for loss\n",
    "    summ = []\n",
    "    loss_avg = RunningAverage()\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    t = trange(num_steps)\n",
    "    for i in t:\n",
    "        # fetch the next training batch\n",
    "        train_batch, labels_batch, _ = next(data_iterator)\n",
    "\n",
    "        # compute model output and loss\n",
    "        output_batch = model(train_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate summaries only once in a while\n",
    "        if i % 10 == 0:\n",
    "            # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "            output_batch = output_batch.data.cpu().numpy()\n",
    "            labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "            # compute all metrics on this batch\n",
    "            # summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "            #                  for metric in metrics}\n",
    "            # summary_batch['loss'] = loss.item()\n",
    "            # summ.append(summary_batch)\n",
    "\n",
    "        # update the average loss\n",
    "        loss_avg.update(loss.item())\n",
    "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    # metrics_mean = {metric: np.mean([x[metric]\n",
    "    #                                  for x in summ]) for metric in summ[0]}\n",
    "    # metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
    "    #                             for k, v in metrics_mean.items())\n",
    "    # print(\"- Train metrics: \" + metrics_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1feee96f562ef39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.014871Z",
     "start_time": "2023-10-16T14:37:13.939867Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, data_iterator, metrics, num_steps):\n",
    "    \"\"\"Evaluate the model on `num_steps` batches.\n",
    "\n",
    "    Args:\n",
    "        model: (torch.nn.Module) the neural network\n",
    "        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n",
    "        data_iterator: (generator) a generator that generates batches of data and labels\n",
    "        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n",
    "        params: (Params) hyperparameters\n",
    "        num_steps: (int) number of batches to train on, each of size params.batch_size\n",
    "    \"\"\"\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # summary for current eval loop\n",
    "    summ = []\n",
    "\n",
    "    # compute metrics over the dataset\n",
    "    for _ in range(num_steps):\n",
    "        # fetch the next evaluation batch\n",
    "        data_batch, labels_batch, _ = next(data_iterator)\n",
    "\n",
    "        # compute model output\n",
    "        output_batch = model(data_batch)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "\n",
    "        # extract data from torch Variable, move to cpu, convert to numpy arrays\n",
    "        output_batch = output_batch.data.cpu().numpy()\n",
    "        labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "        # compute all metrics on this batch\n",
    "        # summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "        #                  for metric in metrics}\n",
    "        # summary_batch['loss'] = loss.item()\n",
    "        # summ.append(summary_batch)\n",
    "\n",
    "    # compute mean of all metrics in summary\n",
    "    # print(f\"summ: {summ}\")\n",
    "    # metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]}\n",
    "    # metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    # print(\"- Eval metrics : \" + metrics_string)\n",
    "    # return metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "798027bbaa11f757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.014985Z",
     "start_time": "2023-10-16T14:37:13.951561Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "        model,\n",
    "        train_sentences,\n",
    "        train_labels,\n",
    "        val_sentences,\n",
    "        val_labels,\n",
    "        num_epochs: int,\n",
    "        batch_size: int,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        metrics\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Run one epoch\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "\n",
    "        # compute number of batches in one epoch (one full pass over the training set)\n",
    "        num_steps = (len(train_sentences) + 1) // batch_size\n",
    "        train_data_iterator = data_iterator(\n",
    "            train_sentences, train_labels, len(train_sentences), batch_size, shuffle=True)\n",
    "        train(model, optimizer, loss_fn, train_data_iterator,\n",
    "              metrics, num_steps)\n",
    "\n",
    "        # Evaluate for one epoch on validation set\n",
    "        num_steps = (len(val_sentences) + 1) // batch_size\n",
    "        val_data_iterator = data_iterator(\n",
    "            val_sentences, val_labels, len(val_sentences), batch_size, shuffle=False)\n",
    "        val_metrics = evaluate(\n",
    "            model, loss_fn, val_data_iterator, metrics, num_steps)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e885f54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "def id_to_words(sentence):\n",
    "    new_sentence = [inv_vocab[i] for i in sentence]\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a981f205b1133b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.015072Z",
     "start_time": "2023-10-16T14:37:13.960431Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the accuracy, given the outputs and labels for all tokens. Exclude PADding terms.\n",
    "\n",
    "    Args:\n",
    "        outputs: (np.ndarray) dimension batch_size*seq_len x num_tags - log softmax output of the model\n",
    "        labels: (np.ndarray) dimension batch_size x seq_len where each element is either a label in\n",
    "                [0, 1, ... num_tag-1], or -1 in case it is a PADding token.\n",
    "\n",
    "    Returns: (float) accuracy in [0,1]\n",
    "    \"\"\"\n",
    "\n",
    "    # reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.ravel()\n",
    "\n",
    "    # since PADding tokens have label -1, we can generate a mask to exclude the loss from those terms\n",
    "    mask = (labels >= 0)\n",
    "\n",
    "    # np.argmax gives us the class predicted for each token by the model\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "\n",
    "\n",
    "    # compare outputs with labels and divide by number of tokens (excluding PADding tokens)\n",
    "    return np.sum(outputs == labels)/float(np.sum(mask))\n",
    "\n",
    "\n",
    "\n",
    "def calculate_multiclass_f1_score(outputs, labels):\n",
    "    \n",
    "    labels = labels.ravel()\n",
    "    mask = (labels >= 0)  \n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    outputs = outputs[mask]\n",
    "    labels = labels[mask]\n",
    "    outputs = outputs\n",
    "    labels = labels\n",
    "    outputs = np.expand_dims(outputs, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)\n",
    "    outputs = outputs.tolist()\n",
    "    labels = labels.tolist()\n",
    "    f1= f1_score_seqeval(labels, outputs, mode='strict', scheme=IOB1)\n",
    "    return f1\n",
    "\n",
    "def classification_report_gen(outputs, labels):\n",
    "    labels = labels.ravel()\n",
    "    mask = (labels >= 0)  \n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    outputs = outputs[mask]\n",
    "    labels = labels[mask]\n",
    "    outputs = outputs\n",
    "    labels = labels\n",
    "    outputs = np.expand_dims(outputs, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)\n",
    "    outputs = outputs.tolist()\n",
    "    labels = labels.tolist()\n",
    "    return classification_report(labels, outputs, mode='strict', scheme=IOB1)\n",
    "    \n",
    "def calculate_multiclass_f1_score2(outputs, labels):\n",
    "    \n",
    "    labels = labels.ravel()\n",
    "    mask = (labels >= 0)  \n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    outputs = outputs[mask]\n",
    "    labels = labels[mask]\n",
    "    f1= f1_score(labels, outputs, average='macro')\n",
    "    return f1\n",
    "\n",
    "def calculate_multiclass_f1_score3(outputs, labels):\n",
    "    \n",
    "    labels = labels.ravel()\n",
    "    mask = (labels >= 0)  \n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    outputs = outputs[mask]\n",
    "    labels = labels[mask]\n",
    "    f1= f1_score(labels, outputs, average='micro')\n",
    "    return f1\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'f1_seqeval': calculate_multiclass_f1_score,\n",
    "    'f1_micro': calculate_multiclass_f1_score3,\n",
    "    'f1 macro': calculate_multiclass_f1_score2,\n",
    "    'accuracy': accuracy\n",
    "    # could add more metrics such as accuracy for each token type\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f91f3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aca478d1db5c66ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T14:37:14.520501Z",
     "start_time": "2023-10-16T14:37:13.975258Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 184.26it/s, loss=-0.434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 186.67it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 187.70it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 188.41it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 188.49it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 189.70it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 187.40it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 189.12it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 187.59it/s, loss=-0.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:05<00:00, 181.13it/s, loss=-0.436]\n"
     ]
    }
   ],
   "source": [
    "# manually change vocab size (unique no. of words) and change label size (unique no. of labels) for now\n",
    "model = Net(embedding_weights, 300, 300, no_of_labels)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "if os.path.isfile(\"model_weights2.pth\"):\n",
    "    model.load_state_dict(torch.load('model_weights2.pth'))\n",
    "else:\n",
    "    train_and_evaluate(model, X_train_tokenized_indexified , y_train_formatted , X_val_tokenized_indexified  , y_val_formatted , 10, 5, optimizer, loss_fn, metrics)\n",
    "    torch.save(model.state_dict(), 'model_weights2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9be8268f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "'''Test batch- tensor of n_sentences x max_len_sentence\n",
    "   Labels_batch- tensor of n_sentences x max_len_sentence\n",
    "   Test sentences- list of n_sentences x sentence_length(no padding)'''\n",
    "print(len(X_test_tokenized_indexified))\n",
    "test_data_iterator = data_iterator(X_test_tokenized_indexified , y_test_formatted , len(X_test_tokenized_indexified), len(X_test_tokenized_indexified), shuffle=True)\n",
    "test_batch, labels_batch, test_sentences = next(test_data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d330282b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type test: <class 'torch.Tensor'>\n",
      "len test: 500\n",
      "type label: <class 'torch.Tensor'>\n",
      "len label: 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"type test: {type(test_batch)}\")\n",
    "print(f\"len test: {len(test_batch)}\")\n",
    "print(f\"type label: {type(labels_batch)}\")\n",
    "print(f\"len label: {len(labels_batch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4353673",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_output = model(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17243532",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_output_numpy = model_output.detach().numpy()\n",
    "labels_batch_numpy = labels_batch.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7c3f0d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32md:\\Admin\\Learning\\UniProgrammingProjects\\SC4002_NLP\\Q2_model_last_word.ipynb Cell 23\u001B[0m line \u001B[0;36m1\n\u001B[1;32m----> <a href='vscode-notebook-cell:/d%3A/Admin/Learning/UniProgrammingProjects/SC4002_NLP/Q2_model_last_word.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m f1_score_seqeval \u001B[39m=\u001B[39m calculate_multiclass_f1_score(model_output_numpy, labels_batch_numpy)\n\u001B[0;32m      <a href='vscode-notebook-cell:/d%3A/Admin/Learning/UniProgrammingProjects/SC4002_NLP/Q2_model_last_word.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001B[0m f1_score_macro \u001B[39m=\u001B[39m calculate_multiclass_f1_score2(model_output_numpy, labels_batch_numpy)\n\u001B[0;32m      <a href='vscode-notebook-cell:/d%3A/Admin/Learning/UniProgrammingProjects/SC4002_NLP/Q2_model_last_word.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001B[0m f1_score_micro \u001B[39m=\u001B[39m calculate_multiclass_f1_score3(model_output_numpy, labels_batch_numpy)\n",
      "\u001B[1;32md:\\Admin\\Learning\\UniProgrammingProjects\\SC4002_NLP\\Q2_model_last_word.ipynb Cell 23\u001B[0m line \u001B[0;36m4\n\u001B[0;32m     <a href='vscode-notebook-cell:/d%3A/Admin/Learning/UniProgrammingProjects/SC4002_NLP/Q2_model_last_word.ipynb#X50sZmlsZQ%3D%3D?line=38'>39</a>\u001B[0m outputs \u001B[39m=\u001B[39m outputs\u001B[39m.\u001B[39mtolist()\n\u001B[0;32m     <a href='vscode-notebook-cell:/d%3A/Admin/Learning/UniProgrammingProjects/SC4002_NLP/Q2_model_last_word.ipynb#X50sZmlsZQ%3D%3D?line=39'>40</a>\u001B[0m labels \u001B[39m=\u001B[39m labels\u001B[39m.\u001B[39mtolist()\n\u001B[1;32m---> <a href='vscode-notebook-cell:/d%3A/Admin/Learning/UniProgrammingProjects/SC4002_NLP/Q2_model_last_word.ipynb#X50sZmlsZQ%3D%3D?line=40'>41</a>\u001B[0m f1\u001B[39m=\u001B[39m f1_score_seqeval(labels, outputs, mode\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39mstrict\u001B[39;49m\u001B[39m'\u001B[39;49m, scheme\u001B[39m=\u001B[39;49mIOB1)\n\u001B[0;32m     <a href='vscode-notebook-cell:/d%3A/Admin/Learning/UniProgrammingProjects/SC4002_NLP/Q2_model_last_word.ipynb#X50sZmlsZQ%3D%3D?line=41'>42</a>\u001B[0m \u001B[39mreturn\u001B[39;00m f1\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:350\u001B[0m, in \u001B[0;36mf1_score\u001B[1;34m(y_true, y_pred, average, suffix, mode, sample_weight, zero_division, scheme)\u001B[0m\n\u001B[0;32m    285\u001B[0m \u001B[39m\u001B[39m\u001B[39m\"\"\"Compute the F1 score.\u001B[39;00m\n\u001B[0;32m    286\u001B[0m \n\u001B[0;32m    287\u001B[0m \u001B[39mThe F1 score can be interpreted as a weighted average of the precision and\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    347\u001B[0m \u001B[39m    array([0.5, 1. ])\u001B[39;00m\n\u001B[0;32m    348\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[0;32m    349\u001B[0m \u001B[39mif\u001B[39;00m mode \u001B[39m==\u001B[39m \u001B[39m'\u001B[39m\u001B[39mstrict\u001B[39m\u001B[39m'\u001B[39m \u001B[39mand\u001B[39;00m scheme:\n\u001B[1;32m--> 350\u001B[0m     _, _, f, _ \u001B[39m=\u001B[39m precision_recall_fscore_support_v1(y_true, y_pred,\n\u001B[0;32m    351\u001B[0m                                                     average\u001B[39m=\u001B[39;49maverage,\n\u001B[0;32m    352\u001B[0m                                                     warn_for\u001B[39m=\u001B[39;49m(\u001B[39m'\u001B[39;49m\u001B[39mf-score\u001B[39;49m\u001B[39m'\u001B[39;49m,),\n\u001B[0;32m    353\u001B[0m                                                     beta\u001B[39m=\u001B[39;49m\u001B[39m1\u001B[39;49m,\n\u001B[0;32m    354\u001B[0m                                                     sample_weight\u001B[39m=\u001B[39;49msample_weight,\n\u001B[0;32m    355\u001B[0m                                                     zero_division\u001B[39m=\u001B[39;49mzero_division,\n\u001B[0;32m    356\u001B[0m                                                     scheme\u001B[39m=\u001B[39;49mscheme,\n\u001B[0;32m    357\u001B[0m                                                     suffix\u001B[39m=\u001B[39;49msuffix)\n\u001B[0;32m    358\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m     _, _, f, _ \u001B[39m=\u001B[39m precision_recall_fscore_support(y_true, y_pred,\n\u001B[0;32m    360\u001B[0m                                                  average\u001B[39m=\u001B[39maverage,\n\u001B[0;32m    361\u001B[0m                                                  warn_for\u001B[39m=\u001B[39m(\u001B[39m'\u001B[39m\u001B[39mf-score\u001B[39m\u001B[39m'\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    364\u001B[0m                                                  zero_division\u001B[39m=\u001B[39mzero_division,\n\u001B[0;32m    365\u001B[0m                                                  suffix\u001B[39m=\u001B[39msuffix)\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\metrics\\v1.py:310\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[1;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, **kwargs)\u001B[0m\n\u001B[0;32m    306\u001B[0m         true_sum \u001B[39m=\u001B[39m np\u001B[39m.\u001B[39mappend(true_sum, \u001B[39mlen\u001B[39m(entities_true_type))\n\u001B[0;32m    308\u001B[0m     \u001B[39mreturn\u001B[39;00m pred_sum, tp_sum, true_sum\n\u001B[1;32m--> 310\u001B[0m precision, recall, f_score, true_sum \u001B[39m=\u001B[39m _precision_recall_fscore_support(\n\u001B[0;32m    311\u001B[0m     y_true, y_pred,\n\u001B[0;32m    312\u001B[0m     average\u001B[39m=\u001B[39;49maverage,\n\u001B[0;32m    313\u001B[0m     warn_for\u001B[39m=\u001B[39;49mwarn_for,\n\u001B[0;32m    314\u001B[0m     beta\u001B[39m=\u001B[39;49mbeta,\n\u001B[0;32m    315\u001B[0m     sample_weight\u001B[39m=\u001B[39;49msample_weight,\n\u001B[0;32m    316\u001B[0m     zero_division\u001B[39m=\u001B[39;49mzero_division,\n\u001B[0;32m    317\u001B[0m     scheme\u001B[39m=\u001B[39;49mscheme,\n\u001B[0;32m    318\u001B[0m     suffix\u001B[39m=\u001B[39;49msuffix,\n\u001B[0;32m    319\u001B[0m     extract_tp_actual_correct\u001B[39m=\u001B[39;49mextract_tp_actual_correct\n\u001B[0;32m    320\u001B[0m )\n\u001B[0;32m    322\u001B[0m \u001B[39mreturn\u001B[39;00m precision, recall, f_score, true_sum\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\metrics\\v1.py:124\u001B[0m, in \u001B[0;36m_precision_recall_fscore_support\u001B[1;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001B[0m\n\u001B[0;32m    120\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\u001B[39m'\u001B[39m\u001B[39maverage has to be one of \u001B[39m\u001B[39m{}\u001B[39;00m\u001B[39m'\u001B[39m\u001B[39m.\u001B[39mformat(average_options))\n\u001B[0;32m    122\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[1;32m--> 124\u001B[0m pred_sum, tp_sum, true_sum \u001B[39m=\u001B[39m extract_tp_actual_correct(y_true, y_pred, suffix, scheme)\n\u001B[0;32m    126\u001B[0m \u001B[39mif\u001B[39;00m average \u001B[39m==\u001B[39m \u001B[39m'\u001B[39m\u001B[39mmicro\u001B[39m\u001B[39m'\u001B[39m:\n\u001B[0;32m    127\u001B[0m     tp_sum \u001B[39m=\u001B[39m np\u001B[39m.\u001B[39marray([tp_sum\u001B[39m.\u001B[39msum()])\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\metrics\\v1.py:294\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support.<locals>.extract_tp_actual_correct\u001B[1;34m(y_true, y_pred, suffix, scheme)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mextract_tp_actual_correct\u001B[39m(y_true, y_pred, suffix, scheme):\n\u001B[0;32m    292\u001B[0m     \u001B[39m# If this function is called from classification_report,\u001B[39;00m\n\u001B[0;32m    293\u001B[0m     \u001B[39m# try to reuse entities to optimize the function.\u001B[39;00m\n\u001B[1;32m--> 294\u001B[0m     entities_true \u001B[39m=\u001B[39m kwargs\u001B[39m.\u001B[39mget(\u001B[39m'\u001B[39m\u001B[39mentities_true\u001B[39m\u001B[39m'\u001B[39m) \u001B[39mor\u001B[39;00m Entities(y_true, scheme, suffix)\n\u001B[0;32m    295\u001B[0m     entities_pred \u001B[39m=\u001B[39m kwargs\u001B[39m.\u001B[39mget(\u001B[39m'\u001B[39m\u001B[39mentities_pred\u001B[39m\u001B[39m'\u001B[39m) \u001B[39mor\u001B[39;00m Entities(y_pred, scheme, suffix)\n\u001B[0;32m    296\u001B[0m     target_names \u001B[39m=\u001B[39m \u001B[39msorted\u001B[39m(entities_true\u001B[39m.\u001B[39munique_tags \u001B[39m|\u001B[39m entities_pred\u001B[39m.\u001B[39munique_tags)\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\scheme.py:274\u001B[0m, in \u001B[0;36mEntities.__init__\u001B[1;34m(self, sequences, scheme, suffix, delimiter)\u001B[0m\n\u001B[0;32m    273\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__init__\u001B[39m(\u001B[39mself\u001B[39m, sequences: List[List[\u001B[39mstr\u001B[39m]], scheme: Type[Token], suffix: \u001B[39mbool\u001B[39m \u001B[39m=\u001B[39m \u001B[39mFalse\u001B[39;00m, delimiter: \u001B[39mstr\u001B[39m \u001B[39m=\u001B[39m \u001B[39m'\u001B[39m\u001B[39m-\u001B[39m\u001B[39m'\u001B[39m):\n\u001B[1;32m--> 274\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mentities \u001B[39m=\u001B[39m [\n\u001B[0;32m    275\u001B[0m         Tokens(seq, scheme\u001B[39m=\u001B[39;49mscheme, suffix\u001B[39m=\u001B[39;49msuffix, delimiter\u001B[39m=\u001B[39;49mdelimiter, sent_id\u001B[39m=\u001B[39;49msent_id)\u001B[39m.\u001B[39;49mentities\n\u001B[0;32m    276\u001B[0m         \u001B[39mfor\u001B[39;49;00m sent_id, seq \u001B[39min\u001B[39;49;00m \u001B[39menumerate\u001B[39;49m(sequences)\n\u001B[0;32m    277\u001B[0m     ]\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\scheme.py:275\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    273\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__init__\u001B[39m(\u001B[39mself\u001B[39m, sequences: List[List[\u001B[39mstr\u001B[39m]], scheme: Type[Token], suffix: \u001B[39mbool\u001B[39m \u001B[39m=\u001B[39m \u001B[39mFalse\u001B[39;00m, delimiter: \u001B[39mstr\u001B[39m \u001B[39m=\u001B[39m \u001B[39m'\u001B[39m\u001B[39m-\u001B[39m\u001B[39m'\u001B[39m):\n\u001B[0;32m    274\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mentities \u001B[39m=\u001B[39m [\n\u001B[1;32m--> 275\u001B[0m         Tokens(seq, scheme\u001B[39m=\u001B[39;49mscheme, suffix\u001B[39m=\u001B[39;49msuffix, delimiter\u001B[39m=\u001B[39;49mdelimiter, sent_id\u001B[39m=\u001B[39;49msent_id)\u001B[39m.\u001B[39mentities\n\u001B[0;32m    276\u001B[0m         \u001B[39mfor\u001B[39;00m sent_id, seq \u001B[39min\u001B[39;00m \u001B[39menumerate\u001B[39m(sequences)\n\u001B[0;32m    277\u001B[0m     ]\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\scheme.py:224\u001B[0m, in \u001B[0;36mTokens.__init__\u001B[1;34m(self, tokens, scheme, suffix, delimiter, sent_id)\u001B[0m\n\u001B[0;32m    221\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__init__\u001B[39m(\u001B[39mself\u001B[39m, tokens: List[\u001B[39mstr\u001B[39m], scheme: Type[Token],\n\u001B[0;32m    222\u001B[0m              suffix: \u001B[39mbool\u001B[39m \u001B[39m=\u001B[39m \u001B[39mFalse\u001B[39;00m, delimiter: \u001B[39mstr\u001B[39m \u001B[39m=\u001B[39m \u001B[39m'\u001B[39m\u001B[39m-\u001B[39m\u001B[39m'\u001B[39m, sent_id: \u001B[39mint\u001B[39m \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m):\n\u001B[0;32m    223\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39moutside_token \u001B[39m=\u001B[39m scheme(\u001B[39m'\u001B[39m\u001B[39mO\u001B[39m\u001B[39m'\u001B[39m, suffix\u001B[39m=\u001B[39msuffix, delimiter\u001B[39m=\u001B[39mdelimiter)\n\u001B[1;32m--> 224\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtokens \u001B[39m=\u001B[39m [scheme(token, suffix\u001B[39m=\u001B[39;49msuffix, delimiter\u001B[39m=\u001B[39;49mdelimiter) \u001B[39mfor\u001B[39;49;00m token \u001B[39min\u001B[39;49;00m tokens]\n\u001B[0;32m    225\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mextended_tokens \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtokens \u001B[39m+\u001B[39m [\u001B[39mself\u001B[39m\u001B[39m.\u001B[39moutside_token]\n\u001B[0;32m    226\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39msent_id \u001B[39m=\u001B[39m sent_id\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\scheme.py:224\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    221\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__init__\u001B[39m(\u001B[39mself\u001B[39m, tokens: List[\u001B[39mstr\u001B[39m], scheme: Type[Token],\n\u001B[0;32m    222\u001B[0m              suffix: \u001B[39mbool\u001B[39m \u001B[39m=\u001B[39m \u001B[39mFalse\u001B[39;00m, delimiter: \u001B[39mstr\u001B[39m \u001B[39m=\u001B[39m \u001B[39m'\u001B[39m\u001B[39m-\u001B[39m\u001B[39m'\u001B[39m, sent_id: \u001B[39mint\u001B[39m \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m):\n\u001B[0;32m    223\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39moutside_token \u001B[39m=\u001B[39m scheme(\u001B[39m'\u001B[39m\u001B[39mO\u001B[39m\u001B[39m'\u001B[39m, suffix\u001B[39m=\u001B[39msuffix, delimiter\u001B[39m=\u001B[39mdelimiter)\n\u001B[1;32m--> 224\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtokens \u001B[39m=\u001B[39m [scheme(token, suffix\u001B[39m=\u001B[39;49msuffix, delimiter\u001B[39m=\u001B[39;49mdelimiter) \u001B[39mfor\u001B[39;00m token \u001B[39min\u001B[39;00m tokens]\n\u001B[0;32m    225\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mextended_tokens \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtokens \u001B[39m+\u001B[39m [\u001B[39mself\u001B[39m\u001B[39m.\u001B[39moutside_token]\n\u001B[0;32m    226\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39msent_id \u001B[39m=\u001B[39m sent_id\n",
      "File \u001B[1;32mc:\\Users\\John\\envs\\cz4045_group_assignment\\Lib\\site-packages\\seqeval\\scheme.py:55\u001B[0m, in \u001B[0;36mToken.__init__\u001B[1;34m(self, token, suffix, delimiter)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__init__\u001B[39m(\u001B[39mself\u001B[39m, token: \u001B[39mstr\u001B[39m, suffix: \u001B[39mbool\u001B[39m \u001B[39m=\u001B[39m \u001B[39mFalse\u001B[39;00m, delimiter: \u001B[39mstr\u001B[39m \u001B[39m=\u001B[39m \u001B[39m'\u001B[39m\u001B[39m-\u001B[39m\u001B[39m'\u001B[39m):\n\u001B[0;32m     54\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtoken \u001B[39m=\u001B[39m token\n\u001B[1;32m---> 55\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mprefix \u001B[39m=\u001B[39m Prefixes[token[\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m]] \u001B[39mif\u001B[39;00m suffix \u001B[39melse\u001B[39;00m Prefixes[token[\u001B[39m0\u001B[39;49m]]\n\u001B[0;32m     56\u001B[0m     tag \u001B[39m=\u001B[39m token[:\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m] \u001B[39mif\u001B[39;00m suffix \u001B[39melse\u001B[39;00m token[\u001B[39m1\u001B[39m:]\n\u001B[0;32m     57\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtag \u001B[39m=\u001B[39m tag\u001B[39m.\u001B[39mstrip(delimiter) \u001B[39mor\u001B[39;00m \u001B[39m'\u001B[39m\u001B[39m_\u001B[39m\u001B[39m'\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "f1_score_seqeval = calculate_multiclass_f1_score(model_output_numpy, labels_batch_numpy)\n",
    "f1_score_macro = calculate_multiclass_f1_score2(model_output_numpy, labels_batch_numpy)\n",
    "f1_score_micro = calculate_multiclass_f1_score3(model_output_numpy, labels_batch_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff483ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"f1_score_seqeval: {f1_score_seqeval}\")\n",
    "print(f\"f1_score_macro: {f1_score_macro}\")\n",
    "print(f\"f1_score_micro: {f1_score_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f91d12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_class_report = classification_report_gen(model_output_numpy, labels_batch_numpy)\n",
    "print(f\"model_class_report: \\n{model_class_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42671f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(model_output.detach().numpy(), axis=1)\n",
    "print(f\"sentences_w_words \\n {len(test_sentences)}\")\n",
    "print(f\"predicted_labels \\n {len(predicted_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740d523",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_output = model(test_batch[10].unsqueeze(0))\n",
    "id_to_words(test_sentences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22872d24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_mask = (labels_batch[10] >= 0)\n",
    "sample_label_predict = np.argmax(sample_output.detach().numpy(), axis=1)[sample_mask]\n",
    "sample_label_true = labels_batch[10][sample_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200bfe3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"sample_label_predict: {sample_label_predict}\")\n",
    "print(f\"sample_label_true: {sample_label_true.numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}