{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d171b8e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question 1.2\n",
    "(a) Describe the size (number of sentences) of the training, development and test file for CoNLL2003.\n",
    "Specify the complete set of all possible word labels based on the tagging scheme (IO, BIO,\n",
    "etc.) you chose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8220b72",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62cdb44b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521343a3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "the code below reads and parses a CoNLL-formatted file, extracting sentences and their corresponding NER tags for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14120a0f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_conll_file(file_path):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    tags = []\n",
    "    tag = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace from the line\n",
    "            if len(line) == 0:  # Check if the line is empty, indicating the end of a sentence\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)  # Append the collected sentence to the 'sentences' list\n",
    "                    tags.append(tag)  # Append the collected NER tags to the 'tags' list\n",
    "                sentence = []  # Reset the sentence buffer for the next sentence\n",
    "                tag = []  # Reset the NER tag buffer for the next sentence\n",
    "            else:\n",
    "                parts = line.split()  # Split the line into parts\n",
    "                word = parts[0]  # Extract the word from the line\n",
    "                if word == '-DOCSTART-':  # Check if the word is '-DOCSTART-', a marker often used in CoNLL data\n",
    "                    continue  # Skip this line and continue to the next line\n",
    "                ner_tag = parts[-1]  # Extract the NER tag from the last part of the line\n",
    "                sentence.append(word)  # Add the word to the current sentence\n",
    "                tag.append(ner_tag)  # Add the NER tag to the current tags\n",
    "        if sentence:\n",
    "            sentences.append(sentence)  # Append the last collected sentence\n",
    "            tags.append(tag)  # Append the last collected NER tags\n",
    "    return sentences, tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204605f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "this code extracts and returns the unique tags found within the nested list structure of allTags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8be5fda4",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_unique_tags(allTags):\n",
    "    uniquetags = set()  # Initialize an empty set to store unique tags\n",
    "    flatten_sentences = list(chain(*allTags))  # Flatten the nested 'allTags' list into a single list\n",
    "    for i in flatten_sentences:  # Iterate through the elements of the flattened list\n",
    "        uniquetags.add(i)  # Add each element (tag) to the 'uniquetags' set\n",
    "    return uniquetags  # Return the set containing unique tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ba8ede2d9ce778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:56:11.597932700Z",
     "start_time": "2023-10-23T14:56:11.300143900Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentences in the training data is 14041.\n",
      "The number of sentences in the development data is 3250.\n",
      "The number of sentences in the test data is 3453.\n",
      "The set of NER tags are {'O', 'B-ORG', 'I-ORG', 'B-MISC', 'B-LOC', 'I-MISC', 'I-LOC', 'I-PER'}.\n"
     ]
    }
   ],
   "source": [
    "# reading the data from the files\n",
    "train_data, train_tags = read_conll_file('CoNLL2003_dataset/eng.train')\n",
    "val_data, val_tags = read_conll_file('CoNLL2003_dataset/eng.testa')\n",
    "test_data, test_tags = read_conll_file('CoNLL2003_dataset/eng.testb')\n",
    "\n",
    "# print the number of sentences in the training, development and test dataset\n",
    "print(f\"The number of sentences in the training data is {len(train_data)}.\")\n",
    "print(f\"The number of sentences in the development data is {len(val_data)}.\")\n",
    "print(f\"The number of sentences in the test data is {len(test_data)}.\")\n",
    "\n",
    "# getting all the unique tags in the dataset\n",
    "all_tags = set()\n",
    "all_tags.update(get_unique_tags(train_tags))\n",
    "all_tags.update(get_unique_tags(val_tags))\n",
    "all_tags.update(get_unique_tags(test_tags))\n",
    "\n",
    "# print all the tags\n",
    "print(f\"The set of NER tags are {all_tags}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Choose an example sentence from the training set of CoNLL2003 that has at least two named entities with more than one word. Explain how to form complete named entities from the label for each word, and list all the named entities in this sentence."
   ],
   "id": "33470f3660e80e48"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example sentence in CoNLL2003 training data, along with its NER tag is shown below. Each token in the sentence is in the following format <word_NER tag>.  \n",
    "\n",
    "Tension_O has_O mounted_O since_O Israeli_I-MISC Prime_O Minister_O Benjamin_I-PER Netanyahu_I-PER took_O office_O in_O June_O vowing_O to_O retain_O the_O Golan_I-LOC Heights_I-LOC Israel_B-LOC captured_O from_O Syria_I-LOC in_O the_O 1967_O Middle_I-LOC East_I-LOC war_O ._O  \n",
    "\n",
    "All the named entities in the example sentence are:\n",
    "- Location: Golan Heights, Israel, Middle East, Syria\n",
    "- Miscellaneous: Israeli\n",
    "- Person: Benjamin Netanyahu\n",
    "\n",
    "Taking the phrase “Golan_I-LOC Heights_I-LOC Israel_B-LOC” as an example, using the IOB1 scheme, we see two distinct named entities, Golan Heights and Israel. We know that Israel is another named entity due to the B-LOC tag which separates two named entities of the same TYPE. The I-LOC NER tag shows that the tokens “Golan” and “Heights” are part of the same named entity chunk.  \n",
    "\n",
    "For the named entity “Benjamin_I-PER Netanyahu_I-PER”, we know that “Benjamin” is the start of the named entity as the token has a NER tag I-PER, and the previous token “Minister” has a NER tag O. “Netanyahu” is also part of the named entity chunk as it has the NER tag I-PER, and the token “took” is not part of this chunk as it has a NER tag O. Thus, allowing us to form the named entity “Benjamin Netanyahu”.  \n",
    "\n",
    "We can follow this process to form another named entity, “Middle East”. The token “Middle” denotes the start of the named entity “Middle East” as it has a NER tag I-LOC, while the previous token “1967” has a NER tag O. “East” is also part of the named entity as it has the NER tag I-LOC, and the token “war” is not part of this chunk as it has a NER tag O. Thus, this forms the named entity, “Middle East”.  "
   ],
   "id": "22aeb45562baa595"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
